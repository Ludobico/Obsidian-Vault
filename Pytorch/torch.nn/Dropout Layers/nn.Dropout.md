```python
torch.nn.Dropout(p=0.5, inplace=False)
```

> p -> float
- 요소가 0으로 만들어질 확률입니다. 일반적으로 0.5로 설정되며, 이는 요소의 절반을 평균적으로 5으로 만듭니다.

> inplace -> bool
- `True` 로 설정할 경우, 연산을 인플레이스로 수행합니다. 기본값은 `False` 입니다.

`nn.Dropout` 은 [[Pytorch]] 에서 사용되는 regularization 기법 중 하나로, **입력 텐서의 요소들 중 일부를 랜덤하게 선택하여 0으로 만드는 작업**을 수행합니다. 이 기법은 특히 train 과정에서 과적합(overfitting)을 방지하고, 뉴런들이 서로 과도하게 적응하는 것을 방지하는데 효과적입니다.


```python
import torch
import torch.nn as nn

input_tensor = torch.randn(2,3,4)

dropout = nn.Dropout(p=0.3)

output_tensor = dropout(input_tensor)

print(input_tensor)

print(output_tensor)
```

```
tensor([[[-0.1065,  0.4368,  0.2351,  0.3986],
         [-0.5142, -0.7526,  0.4004, -0.2423],
         [ 0.1830, -0.9693,  0.7704, -1.2107]],

        [[-1.1799,  0.0487,  2.2419, -0.1708],
         [ 0.0868, -0.1384, -1.1567,  0.2084],
         [ 0.4805,  0.1856,  0.8903, -1.5407]]])


tensor([[[-0.1521,  0.0000,  0.3359,  0.5695],
         [-0.7346, -0.0000,  0.5720, -0.3461],
         [ 0.2614, -0.0000,  0.0000, -1.7295]],

        [[-1.6855,  0.0696,  3.2027, -0.2440],
         [ 0.1240, -0.0000, -0.0000,  0.0000],
         [ 0.6864,  0.2651,  1.2718, -2.2011]]])
```

위 예제에서는 입력 텐서 `input_tensor` 의 요소 중 30%가 평균적으로 0으로 만들어지고, 나머지 요소들은

$$
\frac{1}{(1-p)}
$$
로 스케일링된 후 출력 텐서 `output_tensor` 로 반환됩니다.

