ì´ ë¬¸ì„œëŠ” [[MeloTTS]] í•™ìŠµ ì´ì „ì— ìˆ˜í–‰ëœ ì „ì²˜ë¦¬ ê³¼ì •, ê´€ë ¨ ì½”ë“œ, ê·¸ë¦¬ê³  í•™ìŠµ ì¤€ë¹„ ì „ ë‹¨ê³„ì˜ ì „ë°˜ì ì¸ ë‚´ìš©ì„ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.

## Precondition

- [[MeloTTS]]
- mecab (ë¦¬ëˆ…ìŠ¤ ê¸°ë°˜ì¸ ê²½ìš°)

mecab ì„¤ì¹˜ëŠ” ì•„ë˜ì˜ ì»¤ë§¨ë“œë¡œ ì„¤ì¹˜ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.

```bash
apt-get update && apt-get install -y mecab libmecab-dev mecab-ipadic-utf8
```

```
pip install python-mecab-ko
pip install matplotlib==3.7.0
```


## Step 1 : prepare files

ì˜µì‹œë””ì–¸ì˜ [[MeloTTS]] ë¬¸ì„œì— ì²¨ë¶€ëœ `train_preprocess.py`ì™€ `dataset_preprocess.py`, `getenv.py` íŒŒì¼ì„ MeloTTS ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤.

![[Pasted image 20250708114810.png]]

### dataset_preprocess.py

```python
env = GetEnv()
```

ì „ì²´ì ìœ¼ë¡œ ì‚¬ìš©í•  ë°ì´í„°ì…‹ì„ ì €ì¥í•  í´ë” ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì˜ˆì‹œ ì½”ë“œì²˜ëŸ¼ ë³„ë„ë¡œ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´, `getenv.py` íŒŒì¼ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í´ë”ê°€ ìƒì„±ë©ë‹ˆë‹¤.

í´ë”ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ ìë™ ìƒì„±ë©ë‹ˆë‹¤.

```
train
	dataset
	models
	output
```

ê·¸ í›„, [[HuggingFaceğŸ¤—]]ì—ì„œ ìŒì„±-í…ìŠ¤íŠ¸ ê¸°ë°˜ ë°ì´í„°ì…‹ì„ ê²€ìƒ‰í•œ ë’¤, ì›í•˜ëŠ” ë°ì´í„°ì…‹ì˜ `repo_id`ë¥¼ ì•„ë˜ `main.py` ì½”ë“œì— ì¶”ê°€í•©ë‹ˆë‹¤:

```python
if __name__ == "__main__":
    repo_id = "habapchan/genshin-nahida-korean"
    make_meloTTS_dataset(repo_id)
```

`make_meloTTS_dataset` í•¨ìˆ˜ëŠ” HuggingFaceì—ì„œ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ì…‹ì„ MeloTTS í˜•ì‹ì— ë§ê²Œ ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ì´ë©°, ë‹¤ìŒê³¼ ê°™ì€ `kwargs`ë¥¼ ì¸ìë¡œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> text_key -> str , default : transcription

- í…ìŠ¤íŠ¸ ì •ì œë¥¼ ì ìš©í•  Key ê°’ì˜ ì´ë¦„ì…ë‹ˆë‹¤. HuggngFaceì˜ ë°ì´í„°ì…‹ í˜•íƒœì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![[Pasted image 20250708120512.png]]

> speaker_name -> str, default : "KR-default"

- [[MeloTTS]] í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ë©”íƒ€ë°ì´í„°ì…ë‹ˆë‹¤. [[train_from_github]] ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> language_code -> str, default : "KR"

- [[MeloTTS]] í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ë©”íƒ€ë°ì´í„°ì…ë‹ˆë‹¤. [[train_from_github]] ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> apply_re -> bool, default : True

- í…ìŠ¤íŠ¸ë¥¼ ì •ì œ(regex cleaning)ì„ í• ì§€ ê²°ì •í•˜ëŠ” ë¶ˆë¦¬ì–¸ ê°’ì…ë‹ˆë‹¤. `True` ì¼ ê²½ìš° `,` `.` ì„ ì œì™¸í•œ íŠ¹ìˆ˜ë¬¸ìê°€ ì œê±°ë©ë‹ˆë‹¤.

> make_wav -> bool, default : True

- ë°ì´í„°ì…‹ì˜ ì˜¤ë””ì˜¤ë¥¼ `.wav` íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. wav íŒŒì¼ì˜ ì´ë¦„ì€ `korean_{number}.wav` ë¡œ ì €ì¥ë©ë‹ˆë‹¤.

> verbose -> bool, default : False

- ë°ì´í„°ì…‹ì˜ ì •ë³´ë¥¼ ì¶œë ¥í• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.


#### result

`__main__` êµ¬ë¬¸ì˜ ì»¤ë§¨ë“œë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´, ì•„ë˜ì™€ ê°™ì€ ê²°ê³¼ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.

```
DatasetDict({
    train: Dataset({
        features: ['audio', 'speaker', 'language', 'transcription'],
        num_rows: 1476
    })
})
1476it [01:32, 15.95it/s]
Please run the following command manually:
cd path\MeloTTS\melo 
python preprocess_text.py --metadata path\MeloTTS\train\dataset\genshin-nahida-korean\metadata.list
```

```
train
	dataset
		repo_without_id
			korean_0.wav
			korean_1.wav
			...
			metadata.list
		repo_id
	models
	output
```

ì»¤ë§¨ë“œì— ì¶œë ¥ëœ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ìˆœì„œëŒ€ë¡œ ì…ë ¥í•©ë‹ˆë‹¤.

```
cd path\MeloTTS\melo 
python preprocess_text.py --metadata path\MeloTTS\train\dataset\genshin-nahida-korean\metadata.list
```

`train/dataset` ë””ë ‰í† ë¦¬ì— ì•„ë˜ì™€ ê°™ì€ ì¶”ê°€íŒŒì¼ì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

```
config.json
train.list
val.list
ê° korea_{number} ì— ëŒ€ì‘í•˜ëŠ” pt íŒŒì¼
```

`config.json` ì—ì„œ í•™ìŠµí•  íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.

```json
{
  "train": {
    "log_interval": 200,
    "eval_interval": 1000,
    "seed": 52,
    "epochs": 10000,
    "learning_rate": 0.0003,
    "betas": [
      0.8,
      0.99
    ],
    "eps": 1e-09,
    "batch_size": 6,
    "fp16_run": false,
    "lr_decay": 0.999875,
    "segment_size": 16384,
    "init_lr_ratio": 1,
    "warmup_epochs": 0,
    "c_mel": 45,
    "c_kl": 1.0,
    "skip_optimizer": true
  },
  ...
  
```

### train_preprocess.py

`if __name__ == "__main__"` êµ¬ë¬¸ì—ì„œ `train/dataset/repo_without_id` ë¥¼ `target_dir` ë¡œì§€ì •í•œ ë’¤, ì‹¤í–‰í•©ë‹ˆë‹¤.

```python
if __name__ == "__main__":
    target_dir = r"path\genshin-nahida-korean"
    prepare_pretrained_models(target_dir)
```

```
  âœ“ config.json exists
  âœ“ D.pth exists
  âœ“ DUR.pth exists
  âœ“ G_0.pth exists
  âœ“ metadata.list exists
  âœ“ metadata.list.cleaned exists
  âœ“ train.list exists
  âœ“ val.list exists
Please run the following command manually:
cd path\MeloTTS\melo 
bash train.sh path\MeloTTS\train\dataset\genshin-nahida-korean/config.json <num_of_gpus>
```


## Important

ë§¨ ì•„ë˜ ì»¤ë§¨ë“œ

```
bash train.sh path\MeloTTS\train\dataset\genshin-nahida-korean/config.json <num_of_gpus>
```

ë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´ meloTTS/meloì—  **logs** ë¼ëŠ” í´ë”ê°€ ìƒì„±ë˜ë©´ì„œ ì¶”ê°€ì ìœ¼ë¡œ

í•™ìŠµì´ ì‹œì‘ë˜ë©´ **D_0.pth**, **DUR_0.pth**, **G_0.pth** íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.  
ì„¸ íŒŒì¼ì´ ëª¨ë‘ ìƒì„±ë˜ê³  ì²« ë²ˆì§¸ epochê°€ ì‹œì‘ë˜ë©´ í•™ìŠµì„ ì¤‘ë‹¨í•œ ë’¤, ê¸°ì¡´ì— `prepare_pretrained_models.py`ë¥¼ í†µí•´ ë‹¤ìš´ë¡œë“œí•œ **G_0.pth** íŒŒì¼ë¡œ `logs` ë””ë ‰í† ë¦¬ì— ìˆëŠ” í•´ë‹¹ íŒŒì¼ì„ ë®ì–´ì”Œì›ë‹ˆë‹¤.


![[ëª¨ë¸ ë³µì‚¬.png|512]]

![[ëª¨ë¸ ë¶™ì—¬ë„£ê¸°.png]]

ë®ì–´ì”Œìš°ëŠ”ê²Œ ì™„ë£Œë˜ì—ˆë‹¤ë©´, `train.log` íŒŒì¼ì„ ì‚­ì œí•˜ê³  ë‹¤ì‹œí•œ ë²ˆ

```
bash train.sh path\MeloTTS\train\dataset\genshin-nahida-korean/config.json <num_of_gpus>
```

ì•„ë˜ ì»¤ë§¨ë“œë¥¼ í†µí•´ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.

## trainì´ ì‹œì‘ë˜ë„ ëª¨ë¸íŒŒì¼ì´ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤ë©´ ë˜ëŠ” ëª¨ë¸íŒŒì¼ì„ ì§ì ‘ ì§€ì •í•˜ê³  ì‹¶ë‹¤ë©´

- `train.sh` ìŠ¤í¬ë¦½íŠ¸ê°€ ì´ì œ `--pretrain_G`, `--pretrain_D`, `--pretrain_dur`ê¹Œì§€ ë°›ë„ë¡ ìˆ˜ì •ë¨.
    
- ê·¸ëŸ°ë° ì´ ì¸ìë“¤ì´ _ë¹ˆ ë¬¸ìì—´ì¼ ê²½ìš°_, `torchrun` ëª…ë ¹ì–´ì—ì„œëŠ” **í•´ë‹¹ ì˜µì…˜ë“¤ì„ ìƒëµí•˜ê³  ì‹¶ìŒ**.
    
- ë”°ë¼ì„œ `train.sh`ë¥¼ ì‹¤í–‰í•  ë•ŒëŠ” **ì„ íƒì  ì¸ì**ë¥¼ í—ˆìš©í•˜ëŠ” ë°©ì‹ì´ í•„ìš”í•¨.

```bash
CONFIG=$1
GPUS=$2
PRETRAIN_G=$3
PRETRAIN_D=$4
PRETRAIN_DUR=$5

MODEL_NAME=$(basename "$(dirname "$CONFIG")")
PORT=10902

# ì¸ì ì¡°ê±´ë¶€ ì²˜ë¦¬
PRETRAIN_ARGS=""
[ -n "$PRETRAIN_G" ] && PRETRAIN_ARGS="$PRETRAIN_ARGS --pretrain_G $PRETRAIN_G"
[ -n "$PRETRAIN_D" ] && PRETRAIN_ARGS="$PRETRAIN_ARGS --pretrain_D $PRETRAIN_D"
[ -n "$PRETRAIN_DUR" ] && PRETRAIN_ARGS="$PRETRAIN_ARGS --pretrain_dur $PRETRAIN_DUR"

while :
do
  torchrun --nproc_per_node=$GPUS \
           --master_port=$PORT \
           train.py --config "$CONFIG" \
                    --model "$MODEL_NAME" \
                    $PRETRAIN_ARGS

  for PID in $(ps -aux | grep "$CONFIG" | grep python | awk '{print $2}')
  do
    echo $PID
    kill -9 $PID
  done
  sleep 30
done
```

### ì‚¬ìš©ë²•

**ê¸°ì¡´ì²˜ëŸ¼ pretrain ì—†ì´ ì‹¤í–‰í•˜ë ¤ë©´:**


```bash
bash train.sh path/to/config.json 2
```


- `$3`, `$4`, `$5`ê°€ ë¹„ì–´ ìˆê¸° ë•Œë¬¸ì— `--pretrain_*` ì¸ìë“¤ì€ ìë™ìœ¼ë¡œ ìƒëµë©ë‹ˆë‹¤.
    

**pretrain ëª¨ë¸ ê²½ë¡œë¥¼ ì§€ì •í•˜ë ¤ë©´:**

```bash
bash train.sh path/to/config.json 2 path/to/G.pth path/to/D.pth path/to/DUR.pth
```

- ê²½ë¡œê°€ ë¹„ì–´ ìˆì§€ ì•Šìœ¼ë¯€ë¡œ ìë™ìœ¼ë¡œ ì¸ìë“¤ì´ ë¶™ê²Œ ë©ë‹ˆë‹¤.

