![[Pasted image 20250822140612.png]]

대규모 언어 모델(LLM)의 성능은 전통적으로 **파라미터 수의 확장에 따라 증가**하는 것으로 알려져 왔습니다. 그러나 DeepMind의 _Hoffmann et al. (2022)_ 연구는, 단순히 파라미터수를 증가시키는 방식이 연산량(compute)을 비효율적으로 소모하며, 오히려 **데이터 토큰 수의 증가가 모델 성능 향상에 더 큰 기여를 할 수 있음**을 보였습니다. 이를 <font color="#ffff00">친칠라 스케일(Chinchilla Scaling)</font> 이라 하며, 주어진 계산 예산 하에서 최적의 파라미터 수와 데이터 크기의 관계를 규정하는 스케일링 법칙으로 이해됩니다.

## Compute-Optimal formula

$$
C \propto N \cdot D
$$

- $N$ : 파라미터 수
- $D$ : 학습 토큰 수

이때, 특정 연산량 $C$ 가 주어졌을 때 최적의 성능을 내는 $N$ 과 $D$ 의 조합은 다음과 같습니다.

$$
D \approx 20 \cdot N
$$
즉, 파라미터 수와 데이터 수는 대략 선형적 비율을 갖되, 데이터가 파라미터보다 **약 20배 많은 것이 계산 최적(compute-optimal) 조건**임을 의미합니다.


## Full scaling formula

$$
L(N,D) = E + \frac{A}{N^{\alpha}} + \frac{B}{D^{\beta}}
$$

- $E$ : 1.69
- $A$ : 406.4
- $B$ : 410.7
- $\alpha$ : 0.34
- $\beta$ : 0.28
- $N$ : 파라미터 수
- $D$ : 학습 토큰 수

친칠라 스케일은 LLM의 학습 효율성에 있어 근본적인 전환점을 마련하였습니다. **주어진 연산량에서 모델의 성능을 극대화하려면 파라미터 수와 학습 데이터 수는 균형**을 이루어야 한다는 명제를 공식화한 것입니다.

## DAPT 적용 여부

친칠라 스케일은 from scratch pretraining 상황에서, 주어진 compute budget에서 모델 파라미터와 학습 토큰 수의 최적 균형을 찾기 위해 제안된 법칙입니다.

DAPT는 이미 pretrained 모델을 특정 도메인 말뭉치로 추가 학습하는 과정입니다. 따라서, DAPT 에서 친칠라 스케일을 적용하기는 어렵습니다.

## Fine tuning 적용 여부

Supervised Fine-tuning [[SFTTrainer]] 에서는 전체 pretraining과 달리 데이터셋은 질문 + 답변 토큰 합계 수준의 작은 규모와 일반 언어 능력 최적화가 아니라 특정 태스크의 적합도이기때문에 QA SFT는 친칠라 스케일을 적용할 수 없습니다.

