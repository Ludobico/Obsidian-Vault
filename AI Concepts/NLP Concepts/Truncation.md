원본은 [[HuggingFace🤗]] docs의 [Padding and truncation](https://huggingface.co/docs/transformers/pad_truncation) 에서 확인할 수 있습니다.

<font color="#ffff00">Truncation</font> 은 **입력 시퀀스를 모델이 처리할 수 있는 길이로 줄이는 과정**을 말합니다. 특히, 자연어처리에서는 텍스트 데이터를 처리할 때 각 입력의 길이가 다양할 수 있기 때문에, 모든 입력을 일관된 길이로 맞추어주는 것이 중요합니다. 그러나 모델이 처리할 수 있는 최대 길이보다 긴 데이터를 받게 되면, 해당 데이터를 적절히 줄여주어야 합니다. 이때 사용되는 기술이 바로 truncation 입니다.

## Truncation strategy
---

1. Longest First : **가장 긴 시퀀스부터 토큰을 하나씩 제거** 하여, 지정된 최대 길이(`max_length`) 에 맞춥니다. 이 전략은 특히 긴 문서를 처리할 때 유용하게 사용됩니다. 여러 문서 중 가장 긴 문서가 주어진 길이를 초과하는 경우, 그 문서의 토큰을 줄여 나가면서 길이를 조정합니다.

2. Only First/Only Second : 이 전략은 특히 두 개의 시퀀스가 주어지는 상황, 예를 들어 질문과 답변, 문장과 그에 대한 패러프레이징 등의 경우에 사용됩니다. `only_first` 는 첫 번째 시퀀스만을, `only_second` 는 두 번째 시퀀스만을 지정된 최대 길이에 맞추어 줄입니다.

## Importance
---

- 모델 성능 : **과도하게 긴 데이터는 처리 시간과 자원을 더 많이 소모할 뿐만 아니라, 때로는 모델의 학습이나 예측 성능을 저하시킬 수 있습니다.** 적절한 길이로 데이터를 줄이면, 모델이 효율적으로 학습하고 예측할 수 있습니다.

- 일관성 유지 : 모든 입력 데이터를 동일한 길이로 맞추어 처리함으로써, 데이터 배치를 더 효율적으로 처리할 수 있으며, 모델의 일관된 출력을 보장할 수 있습니다.

따라서 truncation은 **입력 데이터를 모델이 효율적으로 처리**할 수 있도록 조정하는 중요한 과정입니다. 특히 입력 데이터의 길이가 모델의 최대 처리 길이를 초과하는 경우, 이를 적절히 줄여 모델이 처리할 수 있는 형태로 만드는 것이 필수적입니다.


## Difference between padding and truncation
---

[[padding]] 과 truncation 모두 자연어 처리에서 입력 데이터의 길이를 일관되게 맞추기 위한 전략이지만, 이 둘은 서로 반대의 작업을 수행합니다. 각각의 개념과 차이점을 구체적으로 살펴보겠습니다.

### padding

- 입력 시퀀스가 모델이 요구하는 최소 길이에 도달하지 못할 때, 또는 배치 내 다른 시퀀스와 길이를 맞추기 위해 사용합니다.
- 짧은 시퀀스에 특정 토큰(e.g padding token)을 추가하여 길이를 인위적으로 늘립니다. 이렇게 하면 모든 입력이 동일한 길이로 처리될 수 있습니다.
- 모델이 처리할 수 있는 표준 길이의 입력을 만듬으로써, 배치 처리가 가능해지고 계산 효율성이 높아집니다.

### truncation

- 입력 시퀀스가 모델이 처리할 수 있는 최대 길이를 초과할 경우 사용합니다.
- 긴 시퀀스의 끝(또는 시작, 또는 중간)에서 토큰을 제거하여 길이를 줄입니다.
- 모델이 처리할 수 있는 길이를 초과하는 입력을 줄여, 모델의 오버헤드를 감소시키고 처리 속도를 개선합니다.

**패딩은 길이를 늘리는 반면, truncation은 길이를 줄입니다.**

패딩은 주로 데이터의 길이가 모델이 요구하는 최소 길이에 미치지 못할 때 사용되며, truncation은 데이터의 길이가 모델이 처리할 수 있는 최대 길이를 초과했을 때 사용됩니다.

truncation은 원본 데이터에서 일부 정보를 제거하므로 데이터 손실이 발생할 수 있습니다. 반면, 패딩은 원본 데이터의 내용을 그대로 유지하면서 길이를 조정합니다.

