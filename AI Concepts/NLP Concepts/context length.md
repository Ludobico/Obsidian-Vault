
`context length` 는 모델이 한 번에 이해하고 처리할 수 있는 전체 문맥의 최개 길이를 의미합니다. 이 길이는 **사용자 입력뿐 아니라 시스템 프롬프트, 이전 대화 내용, 모델이 생성한 응답까지 모두 포함**한 토큰 수로 계산됩니다.

예를 들어, GPT-4-Turbo 의 경우 context length 가 128,000 토큰이므로, 프롬프트와 생성된 응답을 합쳐 이 범위르 넘지 않도록 해야합니다.

이 길이를 넘기면 프롬프트는 **뒤쪽부터 잘립니다.**, 즉, 프롬프트의 끝부분이 제거되고, 앞부분이 유지됩니다.

