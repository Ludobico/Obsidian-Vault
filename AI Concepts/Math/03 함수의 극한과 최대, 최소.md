
## 미분

### 인공지능에서 미분의 필요성

미분을 시작하기에 앞서 인공지능에서 미분이 왜 필요한지 알아봅시다.

인공지능에서 미분은 [[Backward propagation]] 에서 활용됩니다. 정확히는 가중치와 편향의 값을 조절할 때 사용하는데, 용어부터 알아봅시다.

![[Pasted image 20240228155116.png]]

- <font color="#00b050">입력층(input)</font> : 데이터가 입력되는 계층입니다.
- <font color="#00b050">은닉층(hidden)</font> : 입력층과 출력층 사이에 위치하여 복잡한 분류 문제에서 판별 경계를 찾는 데 사용합니다.
- <font color="#00b050">출력층(output)</font> : 활성화 함수 값을 계산하여 출력을 결정합니다.
- <font color="#00b050">가중치(weight)</font> : 각 신호가 결과에 주는 영향력을 조절하는 요소로 가중치가 클수록 해당 신호가 그만큼 더 중요하다는 의미입니다.
- <font color="#00b050">가중합(weighted sum)</font> : 입력 값($x$) 과 가중치($w$) 의 곱을 모두 더한 후 그 값에 편향($b$) 를 더한 값입니다.
$$y = wx + b$$
- <font color="#00b050">편향(bias)</font> : 가중합에 더하는 상수로, 하나의 뉴런에서 활성화 함수를 거쳐 최종으로 출력되는 값을 조절하는 역할을 합니다.
- <font color="#00b050">활성화 함수</font>([[Activation]] function) 가중합의 결과를 놓고 1 또는 0을 출력해서 다음 뉴런으로 보내는데, 이때 0과 1을 판단하는 함수가 활성화 함수입니다. 활성화 함수로는 [[Sigmoid]]  [[ReLU]] 등이 있습니다.

용어에 익숙해졌다면 미분과 인공지능 관계를 알아봅시다.

위 그림에서 각 원(뉴런)의 값을 구하려면 입력 데이터, 가중치, 편향, 활성화 함수만 알면 됩니다. 입력 데이터는 이밎 알고 활성화 함수도 가중합으로 알 수 있는 값이기 때문에 가중치($w$) 와 편향($b$) 만 구하면 됩니다.

그렇다면 가중치와 편향은 어떻게 구할까요? 가중치와 편향은 역전파로 구하는데, 이때 미분을 사용합니다.

위 그림에서 임의의 가중치와 편향을 선택했을 때, 출력 값과 정답의 차이가 4였다고 가정합니다. (실제로는 MSE 알고리즘을 통해 $(|출력 값 - 정답|^2)$) 으로 구해지지만 편의상 차이가 4라고 가정합니다. ) 이때 출력값과 정답의 차이가 0에 가까워지도록 가중치오 편향의 값을 계속 조정하기를 반복합니다.

구체적으로 수식 표현은 다음과 같습니다. 수식은 이해하지 못하더라도, 이러한 수식으로 가중치와 편향의 값이 조정된다는 정도만 알고 넘어갑시다.

---
만약 $w(i) \cdot x(i) > 0$ & $y(i) = -1$ 이면, $w(i+1) = w(i) - \eta(i) \cdot x(i)$ 

만약 $w(i) \cdot x(i) \leq 0$ & $y(i) = 1$ 이면, $w(i+1) = w(i) + \eta(i) \cdot x(i)$ 

- $x(i)$ : 입력 값
- $y(i)$ : 출력 값
- $w(i)$ : 현재 가중치
- $w(i+1)$ : $w(i)$ 의 업데이트 값
- $\eta(i)$ : 학습률($0 \leq \eta \leq 1$)
> 학습률 ( eta )
>한 번 학습할 때 얼만큼 변화를 주는지에 대한 상수로, 학습률 값에 따라 학습 정확도가 달라질 수 있으므로 인공지능에서 매우 중요한 값입니다.


